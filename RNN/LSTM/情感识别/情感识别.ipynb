{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205d2809-4085-4a9d-acc1-0337066676b3",
   "metadata": {},
   "source": [
    "参考地址：[唐国梁Tommy](https://space.bilibili.com/474347248/channel/index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94962796-64ee-4971-b041-000f345f107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73286b46-9c60-4d48-9a16-52cf03ec3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./reviews.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b979b3a-c21d-4453-acbd-086f96ae639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./labels.txt', 'r') as file:\n",
    "    labels = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1abf39d-32d7-4d19-ab30-009b4927e3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive\\nn'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d28103-b7cb-4ab7-90a6-d52c9d335b0c",
   "metadata": {},
   "source": [
    "#### 1. 处理text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3bec226-c2a0-460d-915f-a814f4e07434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去标点符号\n",
    "clean_text = ''.join(  [cha for cha in text if cha not in punctuation]     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8cc333-136f-49f0-909d-04f1b30ebab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = clean_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdf4aa4-6523-418f-9044-4312db071be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e12b6e-e0ee-40d6-8c34-65a7a1616aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t   '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b15b054-26bc-43e2-a0b7-46dea727ae9c",
   "metadata": {},
   "source": [
    "#### 2. 处理label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c209647-9a33-455c-93f9-59101967454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0712583-fd3b-4a32-8b47-37c49931d489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative', 'positive', 'negative', 'positive']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93395dab-9edf-4a6c-8485-4857f18ef68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive :1 negative: 0\n",
    "label_int = np.array(  [1 if x == 'positive' else 0 for x in labels]   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e3d7d1-adb4-4696-b972-97150dcbdd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bb85e6e-72b9-43f0-b202-54d41925ef82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 12500, 0: 12501})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(label_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e3ff0-46cb-4ad9-a064-dee7c75ead53",
   "metadata": {},
   "source": [
    "#### 3. 构建vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91eaf7ba-936b-4dfa-b115-477bd5b4ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word.lower() for sentence in clean_text for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75fa47ce-adeb-4bde-a6e6-0b6d525a6404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', '', 'it', 'ran', 'at']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50e71908-2cc3-4814-af0b-31a3b0d0e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "various_words = [word  for word in set(words)  if word]  # 清理调空字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d2894f6-ab31-4a2f-9d51-9520e890ce0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(various_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39459be-816b-4fcd-ae36-3a90857cee1e",
   "metadata": {},
   "source": [
    "#### 4. int2word and word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e1b3daa-dbfa-4253-85fd-e544d3b51b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_word = dict(enumerate(various_words, 1))\n",
    "word_int = {w: i for i, w in int_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e83ef9c-ee66-4317-8344-84cde6443950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74072, 74072)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_word), len(word_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb7853-6c66-40a4-bef2-998fed9efe94",
   "metadata": {},
   "source": [
    "#### 5. padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "650260f6-7b2b-4a89-84ff-cad54ad3fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理文本太短及过长的样本\n",
    "# 统计文本中，每条评论的长度\n",
    "sentence_length = [  len(sentence.split()) for sentence in clean_text  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ec0b1b4-7601-4ece-83e3-3d90e515cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b9a87d8-467e-4497-8b2a-bd2dd4fe752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sen = min(   sorted(counts.items() )   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e28d213-8693-45b9-9ca0-1a38337118b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2211dee-4078-405b-9965-729e93588c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大评论长度\n",
    "max_sen = max(sorted(counts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3bc487c-3490-4598-83e1-ff3f65d70828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2514, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6141f2c-f9f3-42d6-8d2a-1809a0f5f2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[2514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "928f8ce0-69e3-48b1-a5e7-d7e99ef4d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 min 和 max 对应的索引\n",
    "min_index = [i for i, length in enumerate(sentence_length) if length == min_sen[0]]\n",
    "max_index = [i for i, length in enumerate(sentence_length) if length == max_sen[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5002f6dc-6a89-4c90-b653-0cb257a268b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25000]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a59087d-0f51-4f23-8eba-555641fc82ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3908]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd101d56-de77-4824-bb38-16058b3122ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据索引删除文本中过短，或过长的评论\n",
    "new_text = np.delete(clean_text, min_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fe04cc5-06df-46ba-ba93-cc7ca2e9fe1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25001, 25000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text), len(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b695297e-bf29-4d37-8a08-813c06bae03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text2 = np.delete(new_text, max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3613ee89-c126-4125-a712-5f76d08659f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25001, 24999)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text), len(new_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e8864d5-0dda-44aa-a486-1f3f3ecf0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样需要在标签集中根据索引删除对应的标签\n",
    "new_labels = np.delete(label_int, min_index)\n",
    "new_labels = np.delete(new_labels, max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd5031b4-4dbf-4a21-9c85-85aea7eac2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25001, 24999)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_int), len(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdcdd0fe-7313-4a26-85bf-f9387f898726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t   '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53d86c54-9552-4e7a-a995-ad58ab16e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 将单词映射为整型\n",
    "\n",
    "text_ints = []\n",
    "for sentence in new_text2:\n",
    "    sample = list()\n",
    "    for word in sentence.split():\n",
    "        int_value = word_int[word] # 获取到单词对应的键\n",
    "        sample.append(int_value)\n",
    "    text_ints.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c55b9616-e704-4e45-82c4-f51625d61f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定统一的文本长度，对整个文本数据中的每条评论进行填充或截断\n",
    "# 设定每条评论固定长度为200个单词，不足的评论用0填充，超过的直接截断\n",
    "\n",
    "def reset_text(text, seq_len):\n",
    "    dataset = np.zeros(  (len(text), seq_len)  )  # 超长的补0\n",
    "    \n",
    "    for index, sentence in enumerate(text):\n",
    "        if len(sentence) < seq_len:\n",
    "            dataset[index, :len(sentence)] = sentence\n",
    "        else:\n",
    "            dataset[index, :] = sentence[: seq_len] # 截断\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1600a65-7f6f-434f-8194-04167467527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reset_text(text_ints, seq_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2962f7de-e86e-4767-98d8-c48bfffca675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24999, 200)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e8ee13c-bdc2-44e1-89a8-0a35b1622447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62697., 72211., 33323., 12552., 31884., 17251., 73299., 27908.,\n",
       "       33626., 23906., 60435., 29069., 55246., 45865., 59719., 18591.,\n",
       "        9946., 57217.,  8754., 36693., 55246., 47129.,  4762., 20176.,\n",
       "       27068., 23906.,  8903., 17817.,  7732., 32514., 38070.,  1023.,\n",
       "       17776., 62697., 72211., 64350., 39526., 33323., 12335., 10611.,\n",
       "       38070., 46924., 25639., 33323., 47129., 23906.,  6058., 38070.,\n",
       "         794., 73159., 23906.,  7431., 12469., 68376., 70877., 33260.,\n",
       "       62543., 47388.,  1837.,  1701., 47129., 69580., 23906., 34713.,\n",
       "       55853., 23906., 13278., 27898.,  1045., 53736., 32514., 55853.,\n",
       "       23906., 49258., 47547., 37983., 27266.,  1837., 12469., 48599.,\n",
       "       47547., 39491., 23906., 23727., 27068., 10909., 12552., 15379.,\n",
       "        3572., 26751., 38070., 25736., 16270., 23906., 57217., 47547.,\n",
       "        9347., 30407., 33626., 72211., 12552., 48905., 66388.,  8085.,\n",
       "       47547., 30558., 24592., 38070., 65745., 54996., 55853., 67667.,\n",
       "       47129., 15379., 17529., 38070., 62697., 72211., 47547., 28632.,\n",
       "       17776., 54842., 28262., 55853.,  4762., 57789., 71842., 17776.,\n",
       "       62697., 72211., 33323., 47074., 29782., 66837., 12552.,  4135.,\n",
       "       17776., 73299., 49856.,  8941.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131469ba-4a6b-4e2a-b518-0df9b33387d8",
   "metadata": {},
   "source": [
    "#### 6. 划分训练集和验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5edca041-1f1c-4581-9cc6-0b4278cc29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81db5879-55a4-4596-b9d3-0d993d8216cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset), type(label_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d48691a-5f86-4407-a061-336518f4dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据类型转换\n",
    "dataset_tensor = torch.from_numpy(dataset)\n",
    "label_tensor = torch.from_numpy(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31a9e8f3-7189-4608-95e8-12ecd75f4567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24999, 200]), torch.Size([24999]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tensor.shape, label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ec88b1d-193a-42a3-960f-e2250bc7d3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本数： 24999\n",
      "训练样本数： 19999\n",
      "验证样本数： 2500\n",
      "测试样本数： 2500\n"
     ]
    }
   ],
   "source": [
    "# 数据分割，train, val, test\n",
    "\n",
    "# 总样本数\n",
    "all_samples = len(dataset_tensor)\n",
    "print(\"总样本数：\",all_samples)\n",
    "\n",
    "# 设置比例\n",
    "ratio = 0.8\n",
    "train_size = int(all_samples * 0.8) # 训练样本数\n",
    "print(\"训练样本数：\",train_size)\n",
    "\n",
    "rest_size = all_samples - train_size # 剩余样本数\n",
    "\n",
    "val_size = int(rest_size * 0.5) # 验证样本数\n",
    "print(\"验证样本数：\", val_size)\n",
    "\n",
    "test_size = int(rest_size * 0.5) # 测试样本数\n",
    "print(\"测试样本数：\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f65f9073-eed0-40fd-b843-87ed189d83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取train, val, test 样本\n",
    "\n",
    "# train\n",
    "train = dataset_tensor[:train_size]\n",
    "train_labels = label_tensor[:train_size]\n",
    "\n",
    "# 剩余样本\n",
    "rest_samples = dataset_tensor[train_size:]\n",
    "rest_labels = label_tensor[train_size:]\n",
    "\n",
    "# val\n",
    "val = rest_samples[:val_size]\n",
    "val_labels = rest_labels[:val_size]\n",
    "\n",
    "# test\n",
    "test = rest_samples[val_size:]\n",
    "test_labels = rest_labels[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77cd7968-f550-4f0b-b7b3-09201f29bf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19999, 200]), torch.Size([19999]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d161454-2b58-481d-999e-66addfd923b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2500, 200]), torch.Size([2500]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b918daca-1d97-4b1f-b7f3-d3656f21c481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2500, 200]), torch.Size([2500]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3b262d8-903e-46e2-ae42-01526df0f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过dataLoadder 按批处理数据\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1062dd0-0f8e-4c23-8124-31cd3ffe103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行封装 （评论，标签）\n",
    "train_dataset = TensorDataset(train, train_labels)\n",
    "val_dataset = TensorDataset(val, val_labels)\n",
    "test_dataset = TensorDataset(test, test_labels)\n",
    "\n",
    "batch_size = 128\n",
    "# 批处理\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e031828-2fbe-4f81-82ca-4fdbd3f64f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取train中的第一批数据\n",
    "data, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b19048c-5ad3-4ae7-b124-97bad86b3a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 200]), torch.Size([128]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de48a462-b1d3-4909-a2d8-a69e978517c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f5a90-3f2e-4e3d-a3a3-0e196d0a8ed3",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a507a4c2-b0c6-41dd-9cc5-0323e2fb290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, num_layers, dropout=0.5):\n",
    "        super(sentiment, self).__init__()\n",
    "        \n",
    "        # batch_size = 128\n",
    "        # seq_len=200\n",
    "        \n",
    "        # # 初始化超参数\n",
    "        # vocab_size = len(word_int) + 1 # 输入 不同的单词个数  因为我们的index是从1开始的# 既word_embedding索引为0的 不会被更新。\n",
    "        # output_size = 1 # 输出\n",
    "        # embedding_dim = 400 # 词嵌入维度\n",
    "        # hidden_dim = 128 # 隐藏层节点个数\n",
    "        # num_layers = 2 # lstm的层数\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.ouput_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden): \n",
    "        #print('x.shape:', x.shape)\n",
    "        batch_size = x.size(0) # 获取batch_size\n",
    "        x = x.long()\n",
    "        #print('x.long().shape:', x.shape)\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        # print('Embedding.out.shape:', embeds.shape)\n",
    "        # print('h_0.shape:',   hidden[0].shape)\n",
    "        # print('h_0:',   hidden[0])\n",
    "        # print('c_0.shape:',   hidden[1].shape)\n",
    "        # print('C_0:',   hidden[1])\n",
    "        \n",
    "        #embeds [batch_size, seq_size,embedding_dim(fea_num)] = [128 * 200 * 400]\n",
    "        out, hidden = self.lstm(embeds, hidden)\n",
    "        # out: [batch_size, seq_size, hidden_dim] = [128 * 200 * 128]\n",
    "        \n",
    "        # print('lstm.out:', out.shape)  # [128 * 200 * 128]\n",
    "        # print('lstm.h_n:', hidden[0].shape) #h_n.shape[num_layers, batch_size, hidden_dim] = [2 * 128 * 128]\n",
    "        # print('lstm.c_n:', hidden[1].shape) #c_n.shape[num_layers, batch_size, hidden_dim] = [2 * 128 * 128]\n",
    "        \n",
    "        out = out.reshape(-1, self.hidden_dim)\n",
    "        # out: [25600=128*200, 128]\n",
    "        # print('reshape.out.shape', out.shape)\n",
    "        \n",
    "        out = self.linear(out)\n",
    "        # out: [output_size] = [25600 * 1]\n",
    "        # print('linear.out.shape:', out.shape)\n",
    "        \n",
    "        sigmoid_out = self.sigmoid(out) \n",
    "        # sigmoid_out: [25600 * 1] 维度不变的\n",
    "        # print('Sigmoid.shape:', sigmoid_out.shape)\n",
    "        \n",
    "        sigmoid_out = sigmoid_out.reshape(batch_size, -1)\n",
    "        # sigmoid_out: [128 * 200] 维度不变的\n",
    "        # print('Sigmoid.reshape.shape:', sigmoid_out.shape)\n",
    "        # print('Sigmoid.reshape.shape:', sigmoid_out)\n",
    "        \n",
    "        sigmoid_out = sigmoid_out[:, -1]\n",
    "        # print('last out.shape:', sigmoid_out.shape)\n",
    "        # print('last out.shape:', sigmoid_out)\n",
    "        \n",
    "        # raise Exception('err')\n",
    "        \n",
    "        return sigmoid_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70d1626e-337e-4fb5-9494-1a0e3dcf1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化超参数\n",
    "# seq_len = 200\n",
    "# batch_size = 128\n",
    "# vocab_size = 74073\n",
    "vocab_size = len(word_int) + 1 # 输入 不同的单词个数  因为我们的index是从1开始的# 既word_embedding索引为0的 不会被更新。\n",
    "output_size = 1 # 输出\n",
    "embedding_dim = 400 # 词嵌入维度\n",
    "hidden_dim = 128 # 隐藏层节点个数\n",
    "num_layers = 2 # lstm的层数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d1b22951-f737-4738-a1cf-51862a92091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = sentiment(vocab_size, embedding_dim, hidden_dim, output_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be555f81-2231-4fb9-aab0-2e93fea509da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment(\n",
       "  (embedding): Embedding(74073, 400)\n",
       "  (lstm): LSTM(400, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8508d9-37e9-49ff-bff2-a4cb9a0563f0",
   "metadata": {},
   "source": [
    "### 模型参数分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834be5a-1dd9-4788-89e3-9a39bf55ce25",
   "metadata": {},
   "source": [
    "#### 一：嵌入层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5aa7b-599a-442a-a615-d2a33249465a",
   "metadata": {},
   "source": [
    "* 输入：$\\rm [batch\\_size, seq\\_len] = [128, 200]$\n",
    "\n",
    "```python\n",
    "batch_size = x.size(0) # 获取batch_size\n",
    "x = x.long()\n",
    "\n",
    "self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "embeds = self.embedding(x)\n",
    "```\n",
    "* 输出: $\\rm [batch\\_size, seq\\_len, embedding\\_size] = [128, 200, 400]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9994306-4efb-40fe-9c75-21af0f7be02b",
   "metadata": {},
   "source": [
    "#### 二: LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd219a9-e02e-4316-b0a1-694763f1b416",
   "metadata": {},
   "source": [
    "[LSTM文档](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM)\n",
    "\n",
    "* 输入：接上面输出\n",
    "```python\n",
    "self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "out, hidden = self.lstm(embeds, hidden)\n",
    "```\n",
    "\n",
    "\n",
    "* 输出-out: $\\rm [N,L,D*H_{out}] = [batch\\_size, seq\\_len, 1 \\times hidden\\_size] =  [128, 200, 128]$\n",
    "* 输出-h_n: $\\rm [D \\times num\\_layers, N, H_{out}] = [1 \\times num\\_layers, batch\\_size, hidden\\_size] = [2, 128, 128]$\n",
    "* 输出-c_h: $\\rm [D \\times num\\_layers, N, H_{cell}] = [1 \\times num\\_layers, batch\\_size, hidden\\_size] = [2, 128, 128]$\n",
    "\n",
    "* 作用：\n",
    "1. 相当于把400维的特征，压缩成128维特征\n",
    "2. 当然中间使用了各种门来克服RNN的短时记忆. 尽量做到无损压缩？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c297e972-6a6c-4116-8ec5-f823e76a0db7",
   "metadata": {},
   "source": [
    "#### 三：全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2afd6-d785-4c11-8ea0-9078526a406b",
   "metadata": {},
   "source": [
    "* [文档torch.reshape](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape)\n",
    "\n",
    "```python\n",
    "out = out.reshape(-1, self.hidden_dim)\n",
    "```\n",
    "输出：$[128\\times 200, 128] = [25600, 128]$\n",
    "\n",
    "* [文档nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "\n",
    "```python\n",
    "self.linear = nn.Linear(hidden_dim, output_size) # input_size=hidden_dim=128 这个参数是对接上一层的输入的, 必须对齐上一次的输出\n",
    "out = self.linear(out)\n",
    "```\n",
    "输出：$\\rm [*, H_{out}=out\\_features=1] = [25600, 1]$\n",
    "\n",
    " where all but the last dimension are the same shape as the input\n",
    " \n",
    " 除了最后一个维度，其他的跟输入维度一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19dc14a-0c34-45ae-94f6-c8ebf2406d13",
   "metadata": {},
   "source": [
    "#### 四：输出层（分类）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28511692-1f39-4507-b6c9-61e79108126e",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "sigmoid_out = self.sigmoid(out) # 输出每个句子的类别概率分布 sigmoid不改变输入数据的形状\n",
    "```\n",
    "\n",
    "输出：$\\rm [25600, 1]$\n",
    "\n",
    "```python\n",
    "sigmoid_out = sigmoid_out.reshape(batch_size, -1)\n",
    "```\n",
    "输出：$\\rm [128, ?] = [128, 200]$\n",
    "\n",
    "```python\n",
    "sigmoid_out = sigmoid_out[:, -1]\n",
    "```\n",
    "输出: $\\rm [128]$ 取了最后一列， 为啥取最后一列？\n",
    "\n",
    "[二元交叉熵损失](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a1e32-3f1d-47ce-b89f-fe15420dec40",
   "metadata": {},
   "source": [
    "#### 五：总结\n",
    "\n",
    "1. 嵌入层：128 * 200的句子阵列，经过嵌入层，变成 128 * 200 * 400 。 相当于完成了word2vec。  1个单词->400特征维度\n",
    "2. lsmt层：128 * 200 * 400， 将特征压缩为 128 * 200 * 128                              400特征维度-> 变128维特征\n",
    "3. 全连接层：将lstm的输出out, reshape到最后一个维度是128维特征（是为了保持语义对齐？半个单词扔入下一层?。）输出特征维度必须是1，便于接sogmoid完成二分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0a85f-256e-48e6-ba53-ce5d4c06204a",
   "metadata": {},
   "source": [
    "#### 六：参数日志\n",
    "```python\n",
    "x.shape: torch.Size([128, 200])\n",
    "x.long().shape: torch.Size([128, 200])\n",
    "Embedding.out.shape: torch.Size([128, 200, 400])\n",
    "h_0.shape: torch.Size([2, 128, 128])\n",
    "h_0: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         ...,\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
    "\n",
    "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         ...,\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
    "c_0.shape: torch.Size([2, 128, 128])\n",
    "C_0: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         ...,\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
    "\n",
    "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         ...,\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
    "lstm.out: torch.Size([128, 200, 128])\n",
    "lstm.h_n: torch.Size([2, 128, 128])\n",
    "lstm.c_n: torch.Size([2, 128, 128])\n",
    "reshape.out.shape torch.Size([25600, 128])\n",
    "linear.out.shape: torch.Size([25600, 1])\n",
    "Sigmoid.shape: torch.Size([25600, 1])\n",
    "Sigmoid.reshape.shape: torch.Size([128, 200])\n",
    "Sigmoid.reshape.shape: tensor([[0.4760, 0.4678, 0.4703,  ..., 0.4949, 0.4902, 0.4752],\n",
    "        [0.4901, 0.4839, 0.4789,  ..., 0.4729, 0.4694, 0.4691],\n",
    "        [0.4876, 0.4865, 0.4863,  ..., 0.4751, 0.4749, 0.4814],\n",
    "        ...,\n",
    "        [0.4786, 0.4785, 0.4747,  ..., 0.4837, 0.4819, 0.4820],\n",
    "        [0.4817, 0.4824, 0.4814,  ..., 0.4794, 0.4776, 0.4740],\n",
    "        [0.4742, 0.4786, 0.4758,  ..., 0.4801, 0.4867, 0.4926]],\n",
    "       grad_fn=<ReshapeAliasBackward0>)\n",
    "last out.shape: torch.Size([128])\n",
    "last out.shape: tensor([0.4752, 0.4691, 0.4814, 0.4681, 0.4697, 0.4922, 0.4769, 0.4800, 0.4899,\n",
    "        0.4674, 0.4897, 0.4811, 0.4813, 0.4744, 0.4880, 0.4758, 0.4850, 0.4868,\n",
    "        0.4915, 0.4682, 0.4884, 0.4724, 0.4829, 0.4729, 0.4691, 0.4802, 0.4709,\n",
    "        0.4707, 0.4906, 0.4702, 0.4837, 0.4818, 0.4754, 0.4862, 0.4534, 0.4722,\n",
    "        0.4651, 0.4451, 0.4810, 0.4856, 0.4892, 0.4785, 0.4865, 0.4763, 0.4716,\n",
    "        0.4931, 0.4601, 0.4717, 0.4765, 0.4740, 0.4830, 0.4815, 0.4913, 0.4778,\n",
    "        0.4749, 0.4700, 0.4896, 0.4720, 0.4680, 0.4752, 0.4854, 0.4779, 0.4686,\n",
    "        0.4798, 0.4728, 0.4898, 0.4675, 0.4702, 0.4727, 0.4803, 0.4757, 0.4830,\n",
    "        0.4788, 0.4707, 0.4817, 0.4762, 0.4861, 0.4802, 0.4785, 0.4819, 0.4918,\n",
    "        0.4630, 0.4900, 0.4705, 0.4633, 0.4680, 0.4946, 0.4583, 0.4794, 0.4937,\n",
    "        0.4784, 0.4671, 0.4887, 0.4868, 0.4811, 0.4697, 0.4739, 0.4957, 0.4735,\n",
    "        0.4730, 0.4699, 0.4693, 0.4680, 0.4783, 0.4637, 0.4902, 0.4606, 0.4828,\n",
    "        0.4750, 0.4750, 0.4787, 0.4750, 0.4773, 0.4816, 0.4640, 0.4849, 0.4769,\n",
    "        0.4760, 0.4776, 0.4766, 0.4827, 0.4769, 0.4860, 0.4850, 0.4831, 0.4820,\n",
    "        0.4740, 0.4926], grad_fn=<SelectBackward0>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5daf8-4a9f-430e-a291-c3e2b49c8e1b",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d3ca992-7a2a-4c33-8995-21fe70beded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss() # 损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # 优化器\n",
    "num_epochs = 10 # 循环次数\n",
    "# num_epochs = 1 # 循环次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f7a116e-1580-49d0-b4f4-4dd19141b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f0c9edf3-c4e4-44c8-9888-c3736416638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练模型\n",
    "def train(model, device, data_loader, criterion, optimizer, num_epochs, val_loader):\n",
    "    history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        hs = model.init_hidden(batch_size)\n",
    "        train_loss = []\n",
    "        train_correct = 0.0\n",
    "        model.train()\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output, hs = model(data, hs) # 模型训练\n",
    "            hs = tuple(  [h.data for h in hs]  )\n",
    "            # output.shape) # torch.Size([128])\n",
    "            loss = criterion(output, target.float()) # 计算损失\n",
    "            train_loss.append(loss.item()) # 累计损失\n",
    "            loss.backward() # 反向传播\n",
    "            optimizer.step() # 参数更新\n",
    "            train_correct += torch.sum(output==target) # 比较\n",
    "            \n",
    "        # 模型严重\n",
    "        model.eval()\n",
    "        hs = model.init_hidden(batch_size)\n",
    "        val_loss = []\n",
    "        val_correct = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                preds, hs = model(data, hs) # 验证\n",
    "                hs = tuple([h.data for h in hs])\n",
    "                \n",
    "                losss = criterion(preds, target.float()) # 计算损失\n",
    "                \n",
    "                val_loss.append(loss.item()) # 累计损失\n",
    "                \n",
    "                val_correct += torch.sum(preds==target) # 比较\n",
    "                \n",
    "        print(f'Epoch {epoch}/{num_epochs} --- train loss {np.round(np.mean(train_loss), 5)} --- val loss {np.round(np.mean(val_loss),5)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bddebf2f-cf13-4c49-ac3d-a090d0aaab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 --- train loss 0.47734 --- val loss 0.40428\n",
      "Epoch 1/10 --- train loss 0.25807 --- val loss 0.35364\n",
      "Epoch 2/10 --- train loss 0.16648 --- val loss 0.19105\n",
      "Epoch 3/10 --- train loss 0.10943 --- val loss 0.13632\n",
      "Epoch 4/10 --- train loss 0.09124 --- val loss 0.04716\n",
      "Epoch 5/10 --- train loss 0.08076 --- val loss 0.04988\n",
      "Epoch 6/10 --- train loss 0.09673 --- val loss 0.12098\n",
      "Epoch 7/10 --- train loss 0.07418 --- val loss 0.17525\n",
      "Epoch 8/10 --- train loss 0.06416 --- val loss 0.06349\n",
      "Epoch 9/10 --- train loss 0.05212 --- val loss 0.01537\n"
     ]
    }
   ],
   "source": [
    "train(model, device, train_loader, criterion, optimizer, num_epochs, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d080536c-0005-4f76-8f76-c414ce972787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "def test(model, data_loader, device, criterion):\n",
    "    test_losses = []\n",
    "    num_correct = 0\n",
    "    # 初始化隐藏状态\n",
    "    hs = model.init_hidden(batch_size)\n",
    "    model.eval()\n",
    "    for i, dataset in enumerate(data_loader):\n",
    "        data = dataset[0].to(device) # 部署到device\n",
    "        target = dataset[1].to(device)\n",
    "        output, hs = model(data, hs) # 测试\n",
    "        loss = criterion(output, target.float()) # 计算损失\n",
    "        pred = torch.round(output) # 将预测值进行四舍五入，转换为0 或 1\n",
    "        test_losses.append(loss.item()) # 保存损失\n",
    "        correct_tensor = pred.eq(target.float().view_as(pred)) # 返回一堆True 或 False\n",
    "        correct = correct_tensor.cpu().numpy()\n",
    "        result = np.sum(correct)\n",
    "        num_correct += result\n",
    "        #print(\"num correct : \", num_correct)\n",
    "        print(f'Batch {i}')\n",
    "        print(f'loss : {np.round(np.mean(loss.item()), 3)}')\n",
    "        print(f'accuracy : {np.round(result / len(data), 3) * 100} %')\n",
    "        print()\n",
    "    print(\"总的测试损失 test loss : {:.2f}\".format(np.mean(test_losses)))\n",
    "    print(\"总的测试准确率 test accuracy : {:.2f}\".format(np.mean(num_correct / len(data_loader.dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5420fee6-8f4b-42a1-88ff-ffbe52559e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "loss : 0.759\n",
      "accuracy : 84.39999999999999 %\n",
      "\n",
      "Batch 1\n",
      "loss : 1.245\n",
      "accuracy : 70.3 %\n",
      "\n",
      "Batch 2\n",
      "loss : 1.191\n",
      "accuracy : 73.4 %\n",
      "\n",
      "Batch 3\n",
      "loss : 1.121\n",
      "accuracy : 71.89999999999999 %\n",
      "\n",
      "Batch 4\n",
      "loss : 0.927\n",
      "accuracy : 75.0 %\n",
      "\n",
      "Batch 5\n",
      "loss : 1.022\n",
      "accuracy : 78.10000000000001 %\n",
      "\n",
      "Batch 6\n",
      "loss : 0.965\n",
      "accuracy : 74.2 %\n",
      "\n",
      "Batch 7\n",
      "loss : 0.837\n",
      "accuracy : 77.3 %\n",
      "\n",
      "Batch 8\n",
      "loss : 1.059\n",
      "accuracy : 72.7 %\n",
      "\n",
      "Batch 9\n",
      "loss : 0.947\n",
      "accuracy : 78.10000000000001 %\n",
      "\n",
      "Batch 10\n",
      "loss : 1.221\n",
      "accuracy : 74.2 %\n",
      "\n",
      "Batch 11\n",
      "loss : 0.723\n",
      "accuracy : 76.6 %\n",
      "\n",
      "Batch 12\n",
      "loss : 0.98\n",
      "accuracy : 80.5 %\n",
      "\n",
      "Batch 13\n",
      "loss : 1.237\n",
      "accuracy : 70.3 %\n",
      "\n",
      "Batch 14\n",
      "loss : 0.918\n",
      "accuracy : 74.2 %\n",
      "\n",
      "Batch 15\n",
      "loss : 1.062\n",
      "accuracy : 75.8 %\n",
      "\n",
      "Batch 16\n",
      "loss : 1.031\n",
      "accuracy : 76.6 %\n",
      "\n",
      "Batch 17\n",
      "loss : 0.894\n",
      "accuracy : 78.10000000000001 %\n",
      "\n",
      "Batch 18\n",
      "loss : 0.89\n",
      "accuracy : 76.6 %\n",
      "\n",
      "总的测试损失 test loss : 1.00\n",
      "总的测试准确率 test accuracy : 0.74\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader, device, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d4297-7a00-4184-8821-f0d86e69c4fb",
   "metadata": {},
   "source": [
    "### 预测predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d139b43-b197-45eb-9bce-dd04ce99be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'this movie is so amazing. the plot is attractive. and I really like it.'\n",
    "text = \"\"\"this film lacked something i couldn  t put my finger on at first charisma on the part of the leading actress . this inevitably translated to lack of chemistry when she shared the screen with her leading man . even the romantic scenes came across as being merely the actors at play . it could very well have been the director who miscalculated what he needed from the actors . i just don  t know .  br    br   but could it have been the screenplay  just exactly who was the chef in love with  he seemed more enamored of his culinary skills and restaurant  and ultimately of himself and his youthful exploits  than of anybody or anything else . he never convinced me he was in love with the princess .  br    br   i was disappointed in this movie . but  don  t forget it was nominated for an oscar  so judge for yourself .  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e2292da8-969a-413e-908e-a73935b51dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converts(text):\n",
    "    # 去除标点符号\n",
    "    new_text = ''.join([char for char in text if char not in punctuation])\n",
    "    print('new text:', new_text)\n",
    "    # 文本映射为索引\n",
    "    text_ints = [word_int[word.lower()] for word in new_text.split()]\n",
    "    print(\"文本映射为索引：\\n\", text_ints)\n",
    "    return text_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5cb73948-f782-4672-983b-afdf49e6ace2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new text: this film lacked something i couldn  t put my finger on at first charisma on the part of the leading actress  this inevitably translated to lack of chemistry when she shared the screen with her leading man  even the romantic scenes came across as being merely the actors at play  it could very well have been the director who miscalculated what he needed from the actors  i just don  t know   br    br   but could it have been the screenplay  just exactly who was the chef in love with  he seemed more enamored of his culinary skills and restaurant  and ultimately of himself and his youthful exploits  than of anybody or anything else  he never convinced me he was in love with the princess   br    br   i was disappointed in this movie  but  don  t forget it was nominated for an oscar  so judge for yourself   \n",
      "文本映射为索引：\n",
      " [48840, 56853, 24852, 10937, 47547, 3644, 8941, 15753, 4762, 14110, 11467, 33626, 65442, 57132, 11467, 23906, 46379, 55853, 23906, 5607, 47267, 48840, 48955, 24785, 38070, 24314, 55853, 42406, 48599, 65118, 17250, 23906, 43077, 21600, 20566, 5607, 68727, 33061, 23906, 7497, 61439, 41821, 52397, 55246, 30498, 19773, 23906, 65721, 33626, 67051, 73299, 44709, 61249, 40806, 56442, 53448, 23906, 25412, 68376, 67938, 66837, 66076, 8454, 27500, 23906, 65721, 47547, 63309, 49171, 8941, 33669, 25187, 25187, 15418, 44709, 73299, 56442, 53448, 23906, 29603, 63309, 24485, 68376, 18552, 23906, 59151, 27068, 63856, 21600, 66076, 54163, 40865, 58370, 55853, 6411, 34154, 34767, 27266, 42203, 27266, 22085, 55853, 27071, 27266, 6411, 57018, 61280, 25639, 55853, 46145, 18473, 34655, 47295, 66076, 38090, 9511, 32514, 66076, 18552, 27068, 63856, 21600, 23906, 10428, 25187, 25187, 47547, 18552, 44542, 27068, 48840, 13332, 15418, 49171, 8941, 37605, 73299, 18552, 14524, 11198, 44511, 32511, 30616, 46300, 11198, 18604]\n"
     ]
    }
   ],
   "source": [
    "text_ints = converts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64be6cd9-da44-4f84-ba8f-5dd39c230aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本对齐，sequence_length = 200\n",
    "new_text_ints = reset_text([text_ints], seq_len=200) # 注意这里要添加一个[]，因为，reset_text处理的二维数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "896b4979-e564-48f6-b747-4e7b1d2374ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48840., 56853., 24852., 10937., 47547.,  3644.,  8941., 15753.,\n",
       "         4762., 14110., 11467., 33626., 65442., 57132., 11467., 23906.,\n",
       "        46379., 55853., 23906.,  5607., 47267., 48840., 48955., 24785.,\n",
       "        38070., 24314., 55853., 42406., 48599., 65118., 17250., 23906.,\n",
       "        43077., 21600., 20566.,  5607., 68727., 33061., 23906.,  7497.,\n",
       "        61439., 41821., 52397., 55246., 30498., 19773., 23906., 65721.,\n",
       "        33626., 67051., 73299., 44709., 61249., 40806., 56442., 53448.,\n",
       "        23906., 25412., 68376., 67938., 66837., 66076.,  8454., 27500.,\n",
       "        23906., 65721., 47547., 63309., 49171.,  8941., 33669., 25187.,\n",
       "        25187., 15418., 44709., 73299., 56442., 53448., 23906., 29603.,\n",
       "        63309., 24485., 68376., 18552., 23906., 59151., 27068., 63856.,\n",
       "        21600., 66076., 54163., 40865., 58370., 55853.,  6411., 34154.,\n",
       "        34767., 27266., 42203., 27266., 22085., 55853., 27071., 27266.,\n",
       "         6411., 57018., 61280., 25639., 55853., 46145., 18473., 34655.,\n",
       "        47295., 66076., 38090.,  9511., 32514., 66076., 18552., 27068.,\n",
       "        63856., 21600., 23906., 10428., 25187., 25187., 47547., 18552.,\n",
       "        44542., 27068., 48840., 13332., 15418., 49171.,  8941., 37605.,\n",
       "        73299., 18552., 14524., 11198., 44511., 32511., 30616., 46300.,\n",
       "        11198., 18604.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "79d476bd-4b02-40f5-9b2e-45b2e113c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy to tensor\n",
    "text_tensor  = torch.from_numpy(new_text_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "df304d0b-44f1-4338-aaa5-1bd466ee5283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "67683f4e-93c9-443b-81e5-87f04803c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text_tensor, device):\n",
    "    batch_size = text_tensor.size(0) # 这里是1\n",
    "    hs = model.init_hidden(batch_size) # 初始化隐状态\n",
    "    text_tensor = text_tensor.to(device)\n",
    "    \n",
    "    pred, hs = model(text_tensor, hs) #判断\n",
    "    print('概率值', pred.item())\n",
    "    # 将pred概率值转换为0或1\n",
    "    pred = torch.round(pred)\n",
    "    print('判定值', pred.item())\n",
    "    # 判断\n",
    "    if pred.data == 1:\n",
    "        print('正面评论')\n",
    "    else:\n",
    "        print('反面评论')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e2f04031-1d47-4457-b8b6-371999ca9777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "概率值 0.0018330179154872894\n",
      "判定值 0.0\n",
      "反面评论\n"
     ]
    }
   ],
   "source": [
    "predict(model, text_tensor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6ff21-a488-4ff8-9ab3-aefea667f873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
