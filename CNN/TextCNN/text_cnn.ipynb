{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757c818f-2cd3-4bd4-b4eb-c6f2dc5b7bf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TextCNN\n",
    "\n",
    "* 本案例目标：二分类，判定是保险行业句子为1，非保险的为0\n",
    "\n",
    "* 基本原理：TextCNN是将卷积神经网络CNN应用到文本分类任务，利用多个不同size的kernel来提取句子中的关键信息（类似于多窗口大小的n-gram), 从而能够更好的捕捉局部相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c916b33-cd41-474f-87d2-49f8fcc70d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018ff2f-874d-4af8-9356-0043b5a4680b",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf0f1d6-3b58-4520-acf2-8db206d3bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    res = list(jieba.cut(string, cut_all=False))\n",
    "    # res = list(string)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c3b704-b0a2-4c16-8733-96ebdb62ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "def split_data(df, split=0.7):\n",
    "    df = df.sample(frac=1)\n",
    "    length = len(df)\n",
    "    train_data = df[0:length - 5000]\n",
    "    eval_data = df[length - 5000:]\n",
    "\n",
    "    return train_data, eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49617b60-e52a-4164-9cc4-402a04407e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一长度\n",
    "def padding_seq(X, max_len=10):\n",
    "    return np.array([\n",
    "        np.concatenate([x, [0] * (max_len - len(x))]) if len(x) < max_len else x[:max_len] for x in X\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02093f4a-9bf3-4212-97fa-a216f8972187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据转换成index\n",
    "def seq2index(seq):\n",
    "    seg = tokenize(seq)\n",
    "    seg_index = []\n",
    "    for s in seg:\n",
    "        seg_index.append(vocab.get(s, 1))\n",
    "    return seg_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2206dfbe-a9ba-47c5-b23b-01baf05dd750",
   "metadata": {},
   "source": [
    "#### 构建词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79837efb-ebb9-4659-989a-ef0b9ee1f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建词典\n",
    "def build_vocab(del_word_frequency):\n",
    "    data = pd.read_csv('./data/classification.csv')\n",
    "    segment = data['sentence'].apply(tokenize)\n",
    "\n",
    "    word_frequency = defaultdict(int)\n",
    "    for row in segment:\n",
    "        for i in row:\n",
    "            word_frequency[i] += 1\n",
    "\n",
    "    word_sort = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)  # 根据词频降序排序\n",
    "\n",
    "    f = open('./data/vocab.txt', 'w', encoding='utf-8')\n",
    "    f.write('[PAD]' + \"\\n\" + '[UNK]' + \"\\n\")\n",
    "    for d in word_sort:\n",
    "        if d[1] > del_word_frequency:\n",
    "            f.write(d[0] + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d4c116-69b4-4a02-8a63-3dc8b7f1707b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/wangquanjun/miniforge3/envs/py39/lib/python3.9/site-packages/jieba/dict.txt ...\n",
      "Loading model from cache /var/folders/0t/5qc9q0vn381cwx3337k5ybdh0000gn/T/jieba.cache\n",
      "Loading model cost 0.4187600612640381 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "build_vocab(del_word_frequency=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05168d81-3311-4795-be70-00e543fb9ce7",
   "metadata": {},
   "source": [
    "#### 读取词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aec5f6e-75dd-40b3-aadc-ed0d4eb50ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "import os\n",
    "if os.path.exists('./data/vocab.txt'):\n",
    "    with open('./data/vocab.txt', encoding='utf-8')as file:\n",
    "        for line in file.readlines():\n",
    "            vocab[line.strip()] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9577c0-c4ba-4ea4-ac21-88f4a3bb8dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ee6aa-c068-437f-a67a-b1cd4a65f08a",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d11ee932-e1c4-4bdb-8668-8b7e862ba1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size=100, max_len=10, dropout=0.2):\n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(2, embedding_size))\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(3, embedding_size))\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(4, embedding_size))\n",
    "        \n",
    "        # 池化层\n",
    "        self.max_pool1 = nn.MaxPool1d(kernel_size=max_len-2+1) # 9\n",
    "        self.max_pool2 = nn.MaxPool1d(kernel_size=max_len-3+1) # 8\n",
    "        self.max_pool3 = nn.MaxPool1d(kernel_size=max_len-4+1) # 7\n",
    "        \n",
    "        # 全连接层\n",
    "        self.dense = nn.Linear(6, 1)\n",
    "        \n",
    "        # 正则化\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # [batch_size, seq_len]\n",
    "        embedding = self.embedding(x)\n",
    "        # [batch_size, seq_len, embedding_size]\n",
    "        \n",
    "        \n",
    "        # [batch_size, seq_len, embedding_size] ->增加一个channel->  [batch_size, 1, seq_len, embedding_size]\n",
    "        embedding = embedding.unsqueeze(dim=1)\n",
    "        \n",
    "        \n",
    "        conv1_out = self.conv1(embedding).squeeze(-1)\n",
    "        conv2_out = self.conv2(embedding).squeeze(-1)\n",
    "        conv3_out = self.conv3(embedding).squeeze(-1)\n",
    "        \n",
    "        #[batch_size, seq_len, seq_len-1]\n",
    "        out1 = self.max_pool1(conv1_out)\n",
    "        out2 = self.max_pool2(conv2_out)\n",
    "        out3 = self.max_pool3(conv3_out)\n",
    "        \n",
    "        out = torch.cat([out1, out2, out3], dim=1).squeeze(-1)\n",
    "        \n",
    "        out = self.drop_out(out)\n",
    "        out = self.dense(out)\n",
    "        \n",
    "        out = torch.sigmoid(out).squeeze(-1)\n",
    "        \n",
    "        return out   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643f580-74c5-4528-8afb-9cd5eee081ce",
   "metadata": {},
   "source": [
    "### 模型参数分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cafdd5-38ff-4ab7-a5de-8627b6f34118",
   "metadata": {},
   "source": [
    "#### 一：嵌入层\n",
    "* 输入：$ \\rm x = [batch\\_size, 10] = [batch\\_size, seq\\_len=10]$\n",
    "\n",
    "```python\n",
    "self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "embedding = self.embedding(x)\n",
    "```\n",
    "\n",
    "* 输出：$ \\rm [batch\\_size, seq\\_len, embedding\\_size]=[batch\\_size, 10, 100]$\n",
    "\n",
    "        \n",
    "\n",
    "```python\n",
    "embedding = embedding.unsqueeze(dim=1) # 升维，原因：因为卷积层的输入,需要一个通道维度\n",
    "```\n",
    "\n",
    "* 输出：$ \\rm [batch\\_size, 1, 10, 100] = [batch\\_size, channel\\_size, seq\\_len, embedding\\_size]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ddab2d-f952-4e76-9fd7-00d545bfcf85",
   "metadata": {},
   "source": [
    "#### 二：卷积层\n",
    "\n",
    "* [文档-卷积层](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)\n",
    "\n",
    "* 输入：$ \\rm [batch\\_size, 1, 10, 100] = [batch\\_size, channel\\_size,  height_{in}, width_{in}]$\n",
    "\n",
    "```python\n",
    "self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(2, embedding_size))\n",
    "self.conv2 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(3, embedding_size))\n",
    "self.conv3 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(4, embedding_size))\n",
    "conv1_out = self.conv1(embedding)\n",
    "conv2_out = self.conv2(embedding)\n",
    "conv3_out = self.conv3(embedding)\n",
    "```\n",
    "\n",
    "* 求：$\\rm height_{out}$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\rm\n",
    "height_{out} = \\Big[  \\frac{height_{in} + 2*padding[0] -dilation[0]*(kernel\\_size[0]-1) -1 }{stride[0]}   +1  \\Big]\\\\\n",
    "&\\rm\n",
    "height_{out} = \\Big[  \\frac{height_{in}  -(kernel\\_size[0]-1) -1 }{1}   +1  \\Big]\\\\\n",
    "&\\rm\n",
    "height_{out} = \\Big[  \\frac{10  - (2-1) -1 }{1}   +1 \\Big] = 9 \\\\\n",
    "&\\rm\n",
    "height_{out} = \\Big[  \\frac{10  - (3-1) -1 }{1}   +1 \\Big] = 8 \\\\\n",
    "&\\rm\n",
    "height_{out} = \\Big[  \\frac{10  - (4-1) -1 }{1}   +1 \\Big] = 7 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* 求：$\\rm width_{out}$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\rm\n",
    "width_{out} = \\Big[  \\frac{width_{in} + 2*padding[1] -dilation[1]*(kernel\\_size[1]-1) -1 }{stride[1]}   +1  \\Big]\\\\\n",
    "&\\rm\n",
    "width_{out} = \\Big[  \\frac{width_{in} -(kernel\\_size[1]-1) -1 }{stride[1]}   +1  \\Big]\\\\\n",
    "&\\rm\n",
    "width_{out} = \\Big[  \\frac{100  - (100-1) -1 }{1}   +1 \\Big] = 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "* 输出：$ \\rm [batch\\_size, 2, 9, 1]$\n",
    "* 输出：$ \\rm [batch\\_size, 2, 8, 1]$\n",
    "* 输出：$ \\rm [batch\\_size, 2, 7, 1]$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1e3cc-413a-4730-b609-f295cdd00a88",
   "metadata": {},
   "source": [
    "#### 三：池化层\n",
    "\n",
    "* [最大池化文档-MaxPool1d api](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d)\n",
    "\n",
    "```python\n",
    "conv1_out = conv1_out.squeeze(-1) # 降维，因为池化层MaxPool1d的输入是[N, C, L_out] = [batch_size, channel_size, kernel_zie]\n",
    "conv2_out = conv2_out.squeeze(-1)\n",
    "conv3_out = conv3_out.squeeze(-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451035c5-8f6a-4431-94ca-7a45744d0628",
   "metadata": {},
   "source": [
    "* 输入：$ \\rm [batch\\_size, 2, 9=L_{in}=kernel\\_size]$ \n",
    "* 输入：$ \\rm [batch\\_size, 2, 8]$\n",
    "* 输入：$ \\rm [batch\\_size, 2, 7]$\n",
    "\n",
    "```python\n",
    "self.max_pool1 = nn.MaxPool1d(kernel_size=max_len-2+1) # 9\n",
    "self.max_pool2 = nn.MaxPool1d(kernel_size=max_len-3+1) # 8\n",
    "self.max_pool3 = nn.MaxPool1d(kernel_size=max_len-4+1) # 7\n",
    "out1 = self.max_pool1(conv1_out)\n",
    "out2 = self.max_pool2(conv2_out)\n",
    "out3 = self.max_pool3(conv3_out)\n",
    "```\n",
    "* 求$\\rm L_{out}$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\rm\n",
    "L_{out} = \\Big[  \\frac{L_{in} + 2*padding -dilation*(kernel\\_size-1) -1 }{stride}   +1  \\Big]\\\\\n",
    "&\\rm\n",
    "L_{out} = \\Big[  \\frac{kernel\\_size  -(kernel\\_size-1) -1 }{kernel\\_size}   +1  \\Big]\\\\\n",
    "&\\rm\n",
    "L_{out} = \\Big[  \\frac{0}{kernel\\_size}   +1  \\Big] =1\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* 输出：$\\rm [batch\\_size, 2, 1] = [batch\\_size, channel, L_{out}]$\n",
    "* 输出：$\\rm [batch\\_size, 2, 1]$\n",
    "* 输出：$\\rm [batch\\_size, 2, 1]$\n",
    "\n",
    "\n",
    "* 变成定长\n",
    "\n",
    "```python\n",
    "out = torch.cat([out1, out2, out3], dim=1).squeeze(-1)\n",
    "```\n",
    "* 输出：$\\rm [bach\\_size, 6]=[bach\\_size, 6, 1]=[bach\\_size, 2+2+2, 1]$ 。  并在-1维度降维\n",
    "\n",
    "池化层功能:\n",
    "* 不改变输入channel\n",
    "* 不同长度的句子池化后，变成定长\n",
    "* max pool: 保留了差异？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb520d-1e74-4e81-bf5c-4b54fb4641f9",
   "metadata": {},
   "source": [
    "#### 四：全链接层\n",
    "\n",
    "* [文档nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "\n",
    "```python    \n",
    "self.drop_out = nn.Dropout(dropout) # 正则化\n",
    "out = self.drop_out(out)\n",
    "```\n",
    "\n",
    "* 输入：$\\rm [batch\\_size, 6]$\n",
    "```python\n",
    "self.dense = nn.Linear(6, 1) # 全链接:torch.nn.Linear(in_features, out_features)\n",
    "out = self.dense(out)\n",
    "```\n",
    "* 输出：$\\rm [batch\\_size, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a393faa-ea36-463b-bac9-043d584cf274",
   "metadata": {},
   "source": [
    "```python\n",
    "out = torch.sigmoid(out) # 输出每个句子的类别概率分布 sigmoid不改变输入数据的形状\n",
    "```\n",
    "* 输出：$\\rm [batch\\_size, 1]$  \n",
    "\n",
    "* 降维，在维度-1进行降维，为啥降维？ 好看，32个句子的类别\n",
    "```python\n",
    "out = out.squeeze(-1)\n",
    "```\n",
    "* 输出:$\\rm [batch\\_size]$\n",
    "* 输出:32个句子的类别\n",
    "\n",
    "\n",
    "[二元交叉熵损失](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5403cfb-565f-480d-aa68-14b5a7fbf3be",
   "metadata": {},
   "source": [
    "### 测试下计算图是否存在错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7880c9a-8709-42ee-ab7f-9651e44708a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (embedding): Embedding(2000, 100)\n",
       "  (conv1): Conv2d(1, 2, kernel_size=(2, 100), stride=(1, 1))\n",
       "  (conv2): Conv2d(1, 2, kernel_size=(3, 100), stride=(1, 1))\n",
       "  (conv3): Conv2d(1, 2, kernel_size=(4, 100), stride=(1, 1))\n",
       "  (max_pool1): MaxPool1d(kernel_size=9, stride=9, padding=0, dilation=1, ceil_mode=False)\n",
       "  (max_pool2): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  (max_pool3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dense): Linear(in_features=6, out_features=1, bias=True)\n",
       "  (drop_out): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextCNN(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aad68b-f261-4691-9e45-fd6800370d31",
   "metadata": {},
   "source": [
    "### 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b20eb2c-5275-4e75-ae04-34929399c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fbf942d-6981-479a-8822-a55d4b30d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv('./data/classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d41768-3382-46ac-8822-644bf2ad70cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>最近在安邦长青树中看到什么豁免，这个是什么意思？</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HUTS中有没有适合帆船比赛的保险，我男朋友这周就要开始了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>计划端午节和男朋友自驾去九*山，买保险三天要多少钱？</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>端午我们准备要举行赛龙舟，说是要份保险，什么好</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>老婆买了安*长*树，她在网上投保的，以后缴费怎么办</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sentence  label\n",
       "0       最近在安邦长青树中看到什么豁免，这个是什么意思？      0\n",
       "1  HUTS中有没有适合帆船比赛的保险，我男朋友这周就要开始了      0\n",
       "2     计划端午节和男朋友自驾去九*山，买保险三天要多少钱？      0\n",
       "3        端午我们准备要举行赛龙舟，说是要份保险，什么好      0\n",
       "4      老婆买了安*长*树，她在网上投保的，以后缴费怎么办      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4486afdb-71ee-443f-b461-2a3e77bef206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=32):\n",
    "    df = pd.read_csv('./data/classification.csv')\n",
    "    train_df, eval_df = split_data(df)\n",
    "    train_x = df['sentence']\n",
    "    train_y = df['label']\n",
    "    \n",
    "    eval_x = eval_df['sentence']\n",
    "    eval_y = eval_df['label']\n",
    "    \n",
    "    train_x = padding_seq(train_x.apply(seq2index))\n",
    "    train_y = np.array(train_y)\n",
    "    \n",
    "    train_data_set = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "    train_data_loader = DataLoader(dataset=train_data_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    eval_x = padding_seq(eval_x.apply(seq2index))\n",
    "    return train_data_loader, eval_x, eval_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6efc8e7-11ed-4955-a309-bbfce36f95eb",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbf43254-c292-49de-b44b-2b2f63952a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "def train():\n",
    "    \n",
    "    # 定义模型\n",
    "    model = TextCNN(vocab_size=638, embedding_size=100, max_len=10)\n",
    "    \n",
    "    train_data_loader, eval_x , eval_y = load_data(batch_size=512)\n",
    "    \n",
    "    eval_x = torch.from_numpy(eval_x)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        eval_x = eval_x.cuda().long()\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_func = nn.BCELoss()\n",
    "    \n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for step, (b_x, b_y) in enumerate(train_data_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                b_x = b_x.cuda().long()\n",
    "                b_y = b_y.cuda().long()\n",
    "            \n",
    "            output = model(b_x)\n",
    "            loss = loss_func(output, b_y.float())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 20 == 0:\n",
    "                test_output = model(eval_x)\n",
    "                pred_y = (test_output.cpu().data.numpy() > 0.5).astype(int)\n",
    "                accuracy = float((pred_y == eval_y).astype(int).sum()) / float(eval_y.size)\n",
    "                if accuracy > best_acc:\n",
    "                    best_acc = accuracy\n",
    "                    torch.save(model, './data/text_cnn.model')\n",
    "                    print('save model, accuracy: %.3f' % accuracy)\n",
    "                print('Epoch: ', epoch, '| train loss: %.4f' % loss.cpu().data.numpy(),\n",
    "                      '| test accuracy: %.3f' % accuracy)\n",
    "                \n",
    "    #torch.save(model, './data/text_cnn.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be45c750-77aa-468f-b170-dea94821398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model, accuracy: 0.745\n",
      "Epoch:  0 | train loss: 0.7248 | test accuracy: 0.745\n",
      "save model, accuracy: 0.872\n",
      "Epoch:  1 | train loss: 0.4232 | test accuracy: 0.872\n",
      "save model, accuracy: 0.911\n",
      "Epoch:  2 | train loss: 0.2850 | test accuracy: 0.911\n",
      "save model, accuracy: 0.938\n",
      "Epoch:  3 | train loss: 0.1895 | test accuracy: 0.938\n",
      "save model, accuracy: 0.959\n",
      "Epoch:  4 | train loss: 0.1576 | test accuracy: 0.959\n",
      "save model, accuracy: 0.967\n",
      "Epoch:  5 | train loss: 0.1013 | test accuracy: 0.967\n",
      "save model, accuracy: 0.974\n",
      "Epoch:  6 | train loss: 0.0840 | test accuracy: 0.974\n",
      "save model, accuracy: 0.983\n",
      "Epoch:  7 | train loss: 0.0650 | test accuracy: 0.983\n",
      "save model, accuracy: 0.985\n",
      "Epoch:  8 | train loss: 0.0407 | test accuracy: 0.985\n",
      "save model, accuracy: 0.987\n",
      "Epoch:  9 | train loss: 0.0382 | test accuracy: 0.987\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804384b-eb83-4661-b829-4d93b06e859d",
   "metadata": {},
   "source": [
    "### 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a98f50d6-96cb-4f1d-88de-52a1eb7c663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66d63514-9a3a-4341-a0d0-dad3711cfc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "model = TextCNN(vocab_size=638, embedding_size=100, max_len=10)\n",
    "model = torch.load('./data/text_cnn.model')\n",
    "# 这个model就是一堆的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55469ef4-ae1c-4563-8a32-6c1884c073c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextCNN(\n",
       "  (embedding): Embedding(638, 100)\n",
       "  (conv1): Conv2d(1, 2, kernel_size=(2, 100), stride=(1, 1))\n",
       "  (conv2): Conv2d(1, 2, kernel_size=(3, 100), stride=(1, 1))\n",
       "  (conv3): Conv2d(1, 2, kernel_size=(4, 100), stride=(1, 1))\n",
       "  (max_pool1): MaxPool1d(kernel_size=9, stride=9, padding=0, dilation=1, ceil_mode=False)\n",
       "  (max_pool2): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  (max_pool3): MaxPool1d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dense): Linear(in_features=6, out_features=1, bias=True)\n",
       "  (drop_out): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b7db076-1903-4153-a510-6c49f48b86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_predict(s):\n",
    "    s = seq2index(s)\n",
    "    #s = torch.from_numpy(padding_seq([s])).cuda().long()\n",
    "    s = torch.from_numpy(padding_seq([s]))\n",
    "    out = model(s)\n",
    "    return out.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9d3cefd-5440-444b-8d12-3f8de2e746af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999213], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '我是程序员'\n",
    "classification_predict(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47136d6f-4140-4576-87c0-d6b8cb98b171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20954591], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '为啥只有电子保单'\n",
    "classification_predict(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4c189b7-8958-457a-82c0-f1fb4213599f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00257886], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '为啥只有保险'\n",
    "classification_predict(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab244e3e-536e-41d7-b1ea-021113c572f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00269974], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"最近在安邦长青树中看到什么豁免，这个是什么意思？\"\n",
    "classification_predict(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10d14a92-8a66-494c-a8d1-16f8ccfa5395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99997616], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"你好\"\n",
    "classification_predict(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb646c9a-6933-4cf4-a6ae-c97a918ac8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9318053e-05], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"如何购买保险\"\n",
    "classification_predict(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f580f9-a382-4a8a-ac22-6b51dc04270f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
